# PatchPro Agent Guide

## Overview

The PatchPro Agent is an AI-powered component that takes normalized static analysis findings and generates automated code fixes with explanations.

## Features

- **AI-Powered Fix Generation**: Uses OpenAI GPT models to generate contextual code fixes
- **Guardrails**: Built-in safety limits for diff size and complexity
- **Batch Processing**: Efficiently processes multiple findings
- **Confidence Scoring**: Each fix includes a confidence level (low/medium/high)
- **Markdown Reports**: Generates formatted PR-ready markdown reports

## Quick Start

### Prerequisites

1. Install dependencies:
```bash
pip install -e .
```

2. Set your OpenAI API key:
```bash
export OPENAI_API_KEY='your-api-key-here'
```

### Basic Usage

```bash
# 1. Run analysis first
patchpro analyze your_file.py --output findings.json

# 2. Generate fixes with agent
patchpro agent findings.json --output report.md
```

## Command Reference

### `patchpro agent`

Generate code fixes from normalized findings using AI.

**Usage:**
```bash
patchpro agent [OPTIONS] FINDINGS_FILE
```

**Arguments:**
- `FINDINGS_FILE`: Path to normalized findings JSON file (from `patchpro analyze`)

**Options:**
- `--output, -o PATH`: Output file for markdown report (default: stdout)
- `--base-path, -b PATH`: Base directory for resolving file paths (default: `.`)
- `--model, -m TEXT`: OpenAI model to use (default: `gpt-4o-mini`)
- `--api-key TEXT`: OpenAI API key (or set `OPENAI_API_KEY` env var)

**Examples:**

```bash
# Basic usage with environment variable
export OPENAI_API_KEY='sk-...'
patchpro agent findings.json --output fixes.md

# Specify model and API key inline
patchpro agent findings.json \
  --model gpt-4o \
  --api-key sk-... \
  --output fixes.md

# Use different base path for file resolution
patchpro agent findings.json \
  --base-path /path/to/project \
  --output fixes.md
```

## Configuration

### Environment Variables

- `OPENAI_API_KEY`: Your OpenAI API key (required)
- `PATCHPRO_MODEL`: Default model to use (optional)
- `PATCHPRO_MAX_TOKENS`: Max tokens per request (optional, default: 2000)
- `PATCHPRO_TEMPERATURE`: Temperature for generation (optional, default: 0.1)
- `PATCHPRO_TIMEOUT`: Request timeout in seconds (optional, default: 30)

### Agent Configuration

The agent includes several guardrails:

- **Max Findings Per Request**: 5 (processes in batches)
- **Max Lines Per Diff**: 50 (skips overly complex changes)
- **Temperature**: 0.1 (low for deterministic output)
- **Max Tokens**: 2000 per request

These can be customized by modifying `AgentConfig` in your code:

```python
from patchpro_bot.agent import AgentConfig, PatchProAgent

config = AgentConfig(
    model="gpt-4o",
    max_tokens=3000,
    max_lines_per_diff=100
)

agent = PatchProAgent(config)
```

## Output Format

The agent generates a markdown report with:

1. **Summary Section**
   - Total findings count
   - Number of fixes generated
   - Analysis metadata

2. **Fixes Section** (grouped by file)
   - Confidence indicator (‚úÖ/‚ö†Ô∏è/‚ùì)
   - Explanation of the fix
   - Unified diff format
   
3. **Footer**
   - Attribution
   - Review reminder

### Example Output

```markdown
# üîß PatchPro Code Fixes

## PatchPro Analysis Summary

- **Total Findings:** 19
- **Fixes Generated:** 12
- **Analysis Tool:** ruff
- **Timestamp:** 2025-10-03T12:00:00

## üìù Proposed Fixes

### üìÑ `test_sample.py`

#### Fix 1: ‚úÖ Split multiple imports into separate lines per PEP 8

**Diff:**
\```diff
--- a/test_sample.py
+++ b/test_sample.py
@@ -1,1 +1,2 @@
-import os, sys
+import os
+import sys
\```

---

*Generated by PatchPro AI Code Repair Assistant*
*Review all changes before applying*
```

## Integration with CI/CD

### GitHub Actions Example

```yaml
- name: Run PatchPro Analysis
  run: |
    patchpro analyze . --output findings.json

- name: Generate Fixes
  env:
    OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  run: |
    patchpro agent findings.json --output report.md

- name: Post PR Comment
  uses: actions/github-script@v6
  with:
    script: |
      const fs = require('fs');
      const report = fs.readFileSync('report.md', 'utf8');
      github.rest.issues.createComment({
        issue_number: context.issue.number,
        owner: context.repo.owner,
        repo: context.repo.repo,
        body: report
      });
```

## Best Practices

1. **Review All Fixes**: Always review generated fixes before applying
2. **Test Changes**: Run your test suite after applying fixes
3. **Batch Processing**: For large codebases, process findings in smaller batches
4. **Model Selection**: 
   - Use `gpt-4o-mini` for cost-effective basic fixes
   - Use `gpt-4o` for complex refactoring
5. **API Key Security**: Never commit API keys; use environment variables or secrets

## Troubleshooting

### "OpenAI API key not provided"
- Ensure `OPENAI_API_KEY` is set in your environment
- Or pass `--api-key` flag directly

### "Missing dependency: No module named 'openai'"
```bash
pip install openai
```

### "Could not load source files"
- Check that `--base-path` points to the correct directory
- Ensure file paths in findings.json are relative to base-path

### Rate Limits
- The agent processes findings in batches of 5
- Add delays between batches if hitting rate limits
- Consider using a higher-tier API plan for production

## API Reference

For programmatic usage, see the main classes:

- `PatchProAgent`: Main agent class
- `AgentConfig`: Configuration options
- `GeneratedFix`: Fix result structure
- `AgentResult`: Overall processing result

Example:

```python
from pathlib import Path
from patchpro_bot.agent import PatchProAgent, AgentConfig, load_source_files
from patchpro_bot.analyzer import FindingsAnalyzer

# Load findings
analyzer = FindingsAnalyzer()
findings = analyzer.load_and_normalize("artifact/analysis")

# Load source files
source_files = load_source_files(findings, Path("."))

# Run agent
config = AgentConfig(model="gpt-4o-mini")
agent = PatchProAgent(config)
result = agent.process_findings(findings, source_files)

# Generate report
report = agent.generate_markdown_report(result)
print(report)
```

## Next Steps

- Learn about [CI/DevEx Integration](../docs/requirements.md#3-cidevex)
- Explore [Evaluation and QA](../docs/requirements.md#4-evalqa)
- Check out [Example Workflows](../examples/)
